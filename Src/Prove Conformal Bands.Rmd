
```{r}
library(readxl)
data <- read_excel("../dataset/TrainingSet.xlsx", col_names = TRUE)
```

Libraries:
```{r,'error=FALSE', 'warning=FALSE'}
library(readxl)
library(survival)
library(survminer)
library(dplyr) 
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
```

Summary:
```{r}
summary(data)
```
Conto numero eventi per ogni covariata
```{r}
table(data$Users, data$Status)
table(data$Purpose, data$Status)
table(data$Orbit, data$Status)
table(data$Continent, data$Status)


```
Dalla letteratura risulta che non ho abbastanza eventi per Navigation, Elliptical, Africa, Multinational, Oceania
Simulation work has suggested that at least 10 events need to be observed for each covariate considered, and anything less will lead to problems.
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2376927/

Rimuoviamo queste classi
```{r}
i <- which(data$Purpose == 'Navigation' | data$Orbit == 'Elliptical' | data$Continent == 'Africa' | data$Continent == 'Multinational' | data$Continent == 'Oceania' )
data <- data[-i,]
```

A livello di continenti è un confronto tra America, Asia e Europa: Maggiori potenze economiche 

Controlliamo
```{r}
table(data$Users, data$Status)
table(data$Purpose, data$Status)
table(data$Orbit, data$Status)
table(data$Continent, data$Status)
table(data$Status)
```

```{r}
i <- which(data$Eccentricity == 0)
data$Eccentricity[i] = 1
data$log.Eccentricity <- -log(data$Eccentricity)
```

```{r}
time <- data$`Effective Lifetime`
status <- data$Status

cox <- coxph(Surv(time,status == 'retired') ~  Apogee + log.Eccentricity   +
                Mass + Users + strata(Purpose) + Continent + strata(Orbit), data = data)
summary(cox)

```


reparazione test set
```{r}
test.set <- read_excel("../Dataset/TestSet.xlsx", col_names = TRUE)
```


```{r}
i <- which(test.set$Purpose == 'Navigation' | test.set$Orbit == 'Elliptical' | test.set$Continent == 'Africa' | test.set$Continent == 'Multinational' | test.set$Continent == 'Oceania' )
test.set <- test.set[-i,]
```

```{r}
table(test.set$Users, test.set$Status)
table(test.set$Purpose, test.set$Status)
table(test.set$Orbit, test.set$Status)
table(test.set$Continent, test.set$Status)
table(test.set$Status)
```
Trasformo Eccentricità per avere un miglior grafico dei residui
```{r}
i <- which(test.set$Eccentricity == 0)
test.set$Eccentricity[i] = 1
test.set$log.Eccentricity <- -log(test.set$Eccentricity)
```

```{r}
coxed <- coxed::coxed(cox, newdata = test.set, method="npsf", bootstrap = TRUE, B=750)
predicted_lifetime <- coxed$exp.dur
```


## Conformalized survival analysis

```{r}
if (!require("devtools")){
    install.packages("devtools")
}
devtools::install_github("zhimeir/cfsurvival")
```

```{r}
library('cfsurvival')
```

```{r}
covariates <-c('Apogee','log.Eccentricity','Mass','Users', 'Purpose', 'Continent', 'Orbit' )
X.test <- test.set[, covariates]
X.train <- data[, covariates]
n=dim(X.train)[1]
n_test=dim(X.test)[1]

Event <- ifelse(data$Status == 'censored', FALSE, TRUE )

C = data$`Effective Lifetime`
id=which(data$Status=="retired")

data$`Launch Date` <- as.Date(data$`Launch Date`)
data$`Launch Date` <- as.POSIXct(data$`Launch Date`)
data$`Final Date`<- as.Date(data$`Final Date`)
data$`Final Date` <- as.POSIXct(data$`Final Date`)

C[id]= data$`Final Date`[234] - data$`Launch Date`[id] # Censoring times 

censored_T = data$`Effective Lifetime`

```

```{r}
library('cfsurvival')
```

heuristic way to mitigate this issue is to discard units with small values of C. Consider
a threshold c0, and extract the subpopulation on which C ≥ c0.

```{r}
#trasformo in anni anche i tempi in [id]:
fine_analisi = rep(data$`Final Date`[234], times=length(id))
fine_analisi<- as.Date(fine_analisi)
fine_analisi <- as.POSIXct(fine_analisi)
C[id] = round(as.numeric(fine_analisi - data$`Launch Date`[id])/365, digit = 2)
C

#C.anni <- C/365
#C.anni

```

```{r}
# Running cfsurvival with c0 = 10
c0 <- 8  ## coverage corretto 
pr_list <- rep(0.5, n)  ## provare a cambiare prior 
pr_new_list <- rep(0.5, n_test)
res <- cfsurv(x = X.test, c_list = c0, pr_list = pr_list, pr_new_list = pr_new_list,
             Xtrain = X.train, C = C, event = Event, time = censored_T, 
             alpha = 0.1) #, model = "aft")  


# Examine the result
T <- test.set$`Effective Lifetime`

cat(sprintf("The coverage is %.3f.\n", mean(res <= T)))
```

```{r}
# Assumiamo che 'res' sia l'output della funzione cfsurv

lower_bound <- res
upper_bound <- +Inf 

# Creiamo un dataframe con i limiti inferiori e superiori
df <- data.frame(Index = 1:length(lower_bound), LowerBound = lower_bound, UpperBound = upper_bound)



```




```{r}
# Carichiamo il pacchetto RColorBrewer se non è già installato
if (!require("RColorBrewer")){
    install.packages("RColorBrewer")
}
library('RColorBrewer')
```


```{r}
# Creiamo una palette di colori pastello
pastel_colors <- brewer.pal(12, "Paired")
barplot(rep(1,9), col = pastel_colors, space = 0, border = NA, ylab = "", xlab = "", xaxt = 'n', yaxt = 'n')
```


```{r}
T <- test.set$`Effective Lifetime`
if (!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}
set.seed(10)
# Seleziona casualmente 10 righe dal dataframe
df_sample <- df %>% sample_n(10)
T_sample <- sample(T, 10)

# Crea il grafico con il dataframe campione
ggplot(data=df_sample, aes(x=Index, y=LowerBound)) + 
  geom_segment(aes(xend=Index, yend=Inf), color=pastel_colors[1], size = 3) +
  geom_point(aes(y = T_sample),size=2.5, color = pastel_colors[2]) +
  coord_flip() +
  labs(x = "Index", y = "Confidence Interval and Effective Lifetime",
       title = "Conformal Prediction Interval and Effective Lifetime for Survival Time") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size=12, family="sans", color="black"))
```

