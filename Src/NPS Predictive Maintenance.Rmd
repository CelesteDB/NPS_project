---
title: "NPS Predictive Maintenance"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
library(lubridate)
```

Load Data:
```{r}
train.set <- read_excel("../Dataset/TrainingSet.xlsx", col_names = TRUE)
test.set <- read_excel("../Dataset/TestSet.xlsx", col_names = TRUE)
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
```

Clean Data:
```{r}
# Remove negligible classes
i <- which(train.set$Purpose == 'Navigation' | train.set$Orbit == 'Elliptical' | train.set$Continent == 'Africa' | train.set$Continent == 'Multinational' | train.set$Continent == 'Oceania' )
train.set <- train.set[-i,]

i <- which(test.set$Purpose == 'Navigation' | test.set$Orbit == 'Elliptical' | test.set$Continent == 'Africa' | test.set$Continent == 'Multinational' | test.set$Continent == 'Oceania' )
test.set <- test.set[-i,]

i <- which(data$Purpose == 'Navigation' | data$Orbit == 'Elliptical' | data$Continent == 'Africa' | data$Continent == 'Multinational' | data$Continent == 'Oceania' )
data <- data[-i,]

# Transform eccentricity
i <- which(train.set$Eccentricity == 0)
train.set$Eccentricity[i] = 1
train.set$log.Eccentricity <- -log(train.set$Eccentricity)

i <- which(test.set$Eccentricity == 0)
test.set$Eccentricity[i] = 1
test.set$log.Eccentricity <- -log(test.set$Eccentricity)

i <- which(data$Eccentricity == 0)
data$Eccentricity[i] = 1
data$log.Eccentricity <- -log(data$Eccentricity)
```

Cox Model:
```{r}
time <- train.set$`Effective Lifetime`
status <- train.set$Status

cox <- coxph(Surv(time,status == 'retired') ~ Apogee + log.Eccentricity + Mass + Users + strata(Purpose) + Continent + strata(Orbit), data = train.set)
summary(cox)
```

Compute Baseline Hazard:
```{r}
idx <- which(data$Status == "censored")
data <- data[idx,]
bashaz.data <- basehaz(cox, data, centered=TRUE)
basehax.dataframe <- data.frame(bashaz.data)
```

Compute $\exp(X^T \beta)$:
```{r}
expLP <- predict(cox, data, type = 'risk', reference=c("strata"))
```

Create dataset to retrieve survival curves for each satellite:
```{r}
# Create temp dataframe
surv.data <- data.frame(hazard = numeric(), timeS = numeric(), strata = numeric(), survival = numeric())

# r <-  sample(1:113, 5, replace = FALSE)
# r <- c(1,8,24)
# r <-c(70:80)
r <- c(1,8,30,38, 60, 79)
n <- dim(data)[1]
for (i in 1:n) { # i in r
  haz <- basehax.dataframe[which(basehax.dataframe$strata == i), 1]
  timeS <- basehax.dataframe[which(basehax.dataframe$strata == i), 2]
  strata <- rep(i, length(haz))
  curva <- haz * expLP[i]
  surv <- exp(-cumsum(curva))
  surv.data <- rbind(surv.data, data.frame(hazard = haz, timeS = timeS, strata = strata, survival =  surv))
}
```

Plot of the survival curves:
```{r}
ggplot(surv.data, aes(x = timeS, y = survival, color = factor(strata))) +
  geom_line(size = 1) +
  scale_color_discrete(name = "Strata") +
  labs(x = "Time", y = "Survival Probability", title = "Survival Curves") +
  theme_minimal() +
  theme(panel.grid.major = element_line(colour = "gray", linetype = "dashed"),
        panel.grid.minor = element_blank())
```

Compute 10% quantiles for all satellites, i.e. time for which $S(t)<0.1$:
```{r}
quantiles <- numeric(n)

for(i in 1:n){
  (idx <- which(surv.data$strata == i))
  data_temp <- surv.data[idx,]
  
  # Indice primo istante di tempo in cui la probabilità scende sotto il 10%
  (it <- which(data_temp$survival < 0.1)[1])

  # Tempo in cui la probabilità scende sotto 0.1
  (quantiles[i] <- data_temp$timeS[it])
}

hist(quantiles)
quantiles[order(quantiles)]
```



```{r}
# Converti i tempi in anni in numeri interi
anni_interi <- as.numeric(quantiles)

# Calcola le date a partire da oggi
date_futuro <- as.Date("2023-11-17") + anni_interi * 365 
date_futuro <- na.omit(date_futuro)

# Estrai gli anni e i mesi dalle date future
anni_data <- year(date_futuro)
mesi_data <- factor(month(date_futuro), labels = month.abb, ordered = FALSE)

# Creazione del dataframe con tutte le combinazioni di mese e anno
anni <- seq(as.Date("2023-11-17"), by = "year", length.out = 35)
anni <- year(anni)
mesi <- factor(month.abb, levels = month.abb)  # Converti i mesi in un fattore ordinato
combinazioni_mese_anno <- expand.grid(Mese = mesi, Anno = anni)

# Aggiungi le osservazioni al dataframe (ipotizzando che tu abbia un dataframe di dati chiamato "dati")
dati <- data.frame(Mese = mesi_data,
                   Anno = anni_data)  # Esempio di dati casuali

# Calcola il conteggio delle osservazioni per ogni combinazione di mese e anno
conteggio_osservazioni <- dati %>%
  group_by(Anno, Mese) %>%
  summarise(Count = n())

# Unisci il conteggio delle osservazioni con il dataframe delle combinazioni di mese e anno
dati_completi <- left_join(combinazioni_mese_anno, conteggio_osservazioni, by = c("Anno", "Mese"))

# Riempire eventuali valori mancanti con 0
dati_completi$Count[is.na(dati_completi$Count)] <- 0

# Plot bidimensionale con il conteggio delle osservazioni
ggplot(dati_completi, aes(x = Mese, y = Anno, fill = Count)) +
  geom_tile(color = "black") +
  geom_text(aes(label = Count), color = "black") +
  scale_fill_gradient(low = "white", high = "blue", guide = "legend") +
  labs(x = "Mese", y = "Anno", title = "Conteggio delle osservazioni per mese e anno") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```