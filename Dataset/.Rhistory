'Ap.disc_high'
)
cox16 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox16)
test <- cox.zph(cox16)
test
cox17 <-
coxph(
Surv(time, Status == 'retired') ~ dummy_training_set$`Longitude of GEO` + Users_Commercial + Users_Government + dummy_training_set$`Purpose_Space Science` +  Continent_Americas + Mass.disc_heavy + Pe.disc_medium + Per.disc_long + strata(dummy_training_set$Ap.disc_high), data = dummy_training_set)
summary(cox17)
test <- cox.zph(cox17)
test
cox18 <-
coxph(
Surv(time, Status == 'retired') ~ dummy_training_set$`Longitude of GEO` + Users_Commercial + strata(Users_Government) + dummy_training_set$`Purpose_Space Science` +  Continent_Americas + Mass.disc_heavy + Pe.disc_medium + Per.disc_long + strata(dummy_training_set$Ap.disc_high), data = dummy_training_set)
summary(cox18)
test <- cox.zph(cox18)
test
# Residui
ggcoxdiagnostics(cox18, type = "scaledsch")
plot(predict(cox18), residuals(cox9, type='martingale'),
xlab='Fitted values', ylab='Martingale residuals', main='Residual Plot', las=1)
# Add a line for residual=0
abline(h=0, col='red')
# Fit a smoother for the points
lines(smooth.spline(predict(cox18), residuals(cox18, type='martingale')), col='blue')
ggcoxdiagnostics(cox18, type = "deviance")
library(fastDummies)
# USERS : Levels: Civil Commercial Government Military
dummy_test_set <- dummy_cols(test_set, select_columns = "Users", remove_first_dummy = TRUE)
# PURPOSE : Levels: Communications Earth Observation Navigation Space Science Technology Development
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Purpose", remove_first_dummy = TRUE)
# ORBIT : Levels: Elliptical GEO LEO MEO
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Orbit", remove_first_dummy = TRUE)
# CONTINENT: Levels: Africa Americas Asia Europe Multinational Oceania
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Continent", remove_first_dummy = FALSE)
# training_setset senza Purpose, Users, Continent and Orbit
dummy_test_set <- dummy_test_set[,c(1:2,6:17,19:33)]
Massa.disc <- cut(test_set$Mass, breaks=c(0, 1000, Inf), labels=c("light", "heavy"))
dummy_test_set$Mass.disc <- Massa.disc
Per.disc <- cut(test_set$Period, breaks=c(0, 500, 1000, Inf), labels=c("short", "medium", "long"))
dummy_test_set$Per.disc <- Per.disc
Inc.disc <- cut(test_set$Inclination, breaks=c(-Inf, 40, 70, Inf), labels=c("low", "medium", "high"))
dummy_test_set$Inc.disc <- Inc.disc
Ap.disc <- cut(test_set$Apogee, breaks=c(0, 25000, Inf), labels=c("low", "high"))
dummy_test_set$Ap.disc <- Ap.disc
Pe.disc <- cut(test_set$Perigee, breaks=c(0, 5000, 25000, Inf), labels=c("low","medium","high"))
dummy_test_set$Pe.disc <- Pe.disc
# MASS: Levels: light heavy
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Mass.disc", remove_first_dummy = TRUE)
# PERIOD: Levels: short medium long
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Per.disc", remove_first_dummy = TRUE)
# INCLINATION: Levels: low medium high
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Inc.disc", remove_first_dummy = TRUE)
# PERIGEE: Levels: low medium high
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Pe.disc", remove_first_dummy = TRUE)
# APOGEE: Levels: low high
dummy_test_set <- dummy_cols(dummy_test_set, select_columns = "Ap.disc", remove_first_dummy = TRUE)
dummy_test_set <- dummy_test_set[,c(1:3,6,9:13,15:42)]
dummy_test_set <- dummy_test_set[,-c(25:29)]
#tolgo expected lifetime
dummy_test_set1=dummy_test_set[,-9]
library(coxed)
ed1 <- coxed(cox18, method="npsf")
predlife=ed1$exp.dur
#mean and median of the predicted durations:
ed1$mean
ed1$median
# PLOT: The estimated cumulative baseline hazard function and survivor function
baseline <- gather(ed1$baseline.functions, cbh, survivor, key="survivefunction", value="value")
ggplot(baseline, aes(x=time, y=value)) +
geom_line() +
xlab("Time") +
ylab("Function") +
facet_wrap( ~ survivefunction, scales = "free")
#PREDICTION:
#dummy_test_set2 <- dummy_test_set1[,c(3,9,10,14,19,24,29,26,31)]
#names(dummy_test_set2)
pred <- coxed(cox18, newdata=dummy_test_set2, method="npsf") #ERRORE: LUNGHEZZE DIFFERISCONO. ???????
dim(training_set)
View(dummy_training_set)
names(dummy_test_set1)==names(dummy_training_set)
dummy_test_set2 <- dummy_test_set1[,c(3,9,10,14,19,24,29,26,31)]
names(dummy_test_set2)
class(dummy_test_set1)
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
data <- data[-which(is.na(data$`Expected Lifetime`)),]
set.seed(123)
library(caret)
# Crea un indice di divisione tra training set e test set
index <- createDataPartition(data$`Effective Lifetime`, p = 0.8, list = FALSE)
# Crea il training set utilizzando l'indice
training_set <- data[index, ]
dim(training_set)
# Crea il test set utilizzando l'indice
test_set <- data[-index, ]
dim(test_set)
library(readxl)
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
training_set$Country <- factor(training_set$Country, ordered = F)
print('Country')
table(training_set$Country)
training_set$Continent <- factor(training_set$Continent, ordered = F)
print('Continent')
table(training_set$Continent)
training_set$Users <- factor(training_set$Users, ordered = F)
print('Users')
table(training_set$Users)
training_set$Purpose <- factor(training_set$Purpose, ordered = F)
print('Purpose')
table(training_set$Purpose)
training_set$Orbit <- factor(training_set$Orbit, ordered = F)
print('Class of Orbit')
table(training_set$Orbit)
training_set$Status <- factor(training_set$Status, ordered = F)
print('Status')
table(training_set$Status)
set.seed(0)
training_set <- training_set[sample(nrow(training_set)), ]
#install.packages("fastDummies")
library(fastDummies)
# USERS : Levels: Civil Commercial Government Military
dummy_training_set <- dummy_cols(training_set, select_columns = "Users", remove_first_dummy = TRUE)
# PURPOSE : Levels: Communications Earth Observation Navigation Space Science Technology Development
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Purpose", remove_first_dummy = TRUE)
# ORBIT : Levels: Elliptical GEO LEO MEO
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Orbit", remove_first_dummy = TRUE)
# CONTINENT: Levels: Africa Americas Asia Europe Multinational Oceania
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Continent", remove_first_dummy = TRUE)
# training_setset senza Purpose, Users, Continent and Orbit
dummy_training_set <- dummy_training_set[,c(1:2,6:17,19:33)]
names(dummy_training_set)
dummy_training_set <- dummy_training_set[,c(1:2,6:17,19:32)]
names(dummy_training_set)
table(training_set$Country)
table(training_set$Continent)
library(glmnet)
time <- dummy_training_set$`Effective Lifetime`
status <- dummy_training_set$Status
covariates <-
c(
"Longitude of GEO" ,
"Perigee" ,
"Apogee",
"Eccentricity" ,
"Inclination",
"Period",
"Mass",
"Users_Commercial",
"Users_Government",
"Users_Military",
"Purpose_Earth Observation",
"Purpose_Navigation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Orbit_GEO",
"Orbit_LEO",
"Orbit_MEO",
"Continent_Americas",
"Continent_Asia",
"Continent_Europe",
"Continent_Multinational"
)
n_coef = length(covariates)
lambda.grid <- 10^seq(2, -5 ,length = 100)
cox_model <- cv.glmnet(x = as.matrix(dummy_training_set[,covariates]), y = Surv(time,status == 'retired'), family = "cox", alpha = 0.2, lambda = lambda.grid)
cox_model <- cv.glmnet(x = as.matrix(dummy_training_set[,covariates]), y = Surv(time,status == 'retired'), family = "cox", alpha = 0.2, lambda = lambda.grid)
bestlambda <- cox_model$lambda.min # con lasso lambda è quasi zero
plot(cox_model)
abline(v=log(bestlambda), lty=1)
fitAtLmin <- glmnet(x = as.matrix(dummy_training_set[,covariates]),  y = Surv(time,status == 'retired') ,family="cox",lambda=bestlambda)
coef <- coef(fitAtLmin)
coef
library(glmnet)
time <- dummy_training_set$`Effective Lifetime`
status <- dummy_training_set$Status
covariates <-
c(
"Longitude of GEO" ,
"Perigee" ,
"Apogee",
"Eccentricity" ,
"Inclination",
"Period",
"Mass",
"Users_Commercial",
"Users_Government",
"Users_Military",
"Purpose_Earth Observation",
"Purpose_Navigation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Orbit_GEO",
"Orbit_LEO",
"Orbit_MEO",
"Continent_Americas",
"Continent_Asia",
"Continent_Europe",
"Continent_Multinational"
)
n_coef = length(covariates)
lambda.grid <- 10^seq(2, -5 ,length = 100)
# Adatta un modello di regressione di Cox penalizzato usando glmnet
# alpha = 1 per la penalizzazione L2 (Ridge)
# alpha = 0 per la penalizzazione L1 (Lasso)
cox_model <- cv.glmnet(x = as.matrix(dummy_training_set[,covariates]), y = Surv(time,status == 'retired'), family = "cox", alpha = 0.2, lambda = lambda.grid)
# PROVA A CAMBIARE VALORE DI ALPHA ---> ELASTIC NET FORSE è MEGLIO
print(cox_model)
bestlambda <- cox_model$lambda.min # con lasso lambda è quasi zero
plot(cox_model)
abline(v=log(bestlambda), lty=1)
fitAtLmin <- glmnet(x = as.matrix(dummy_training_set[,covariates]),  y = Surv(time,status == 'retired') ,family="cox",lambda=bestlambda)
coef <- coef(fitAtLmin)
coef
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Inclination",
"Mass",
"Users_Commercial",
"Purpose_Earth Observation",
"Orbit_LEO"
)
cox1 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox1)
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
set.seed(123)
library(caret)
# Crea un indice di divisione tra training set e test set
index <- createDataPartition(data$`Effective Lifetime`, p = 0.8, list = FALSE)
# Crea il training set utilizzando l'indice
training_set <- data[index, ]
dim(training_set)
# Crea il test set utilizzando l'indice
test_set <- data[-index, ]
dim(test_set)
library(readxl)
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
summary(training_set)
training_set$Country <- factor(training_set$Country, ordered = F)
print('Country')
table(training_set$Country)
training_set$Continent <- factor(training_set$Continent, ordered = F)
print('Continent')
table(training_set$Continent)
training_set$Users <- factor(training_set$Users, ordered = F)
print('Users')
table(training_set$Users)
training_set$Purpose <- factor(training_set$Purpose, ordered = F)
print('Purpose')
table(training_set$Purpose)
training_set$Orbit <- factor(training_set$Orbit, ordered = F)
print('Class of Orbit')
table(training_set$Orbit)
training_set$Status <- factor(training_set$Status, ordered = F)
print('Status')
table(training_set$Status)
set.seed(0)
training_set <- training_set[sample(nrow(training_set)), ]
#install.packages("fastDummies")
library(fastDummies)
# USERS : Levels: Civil Commercial Government Military
dummy_training_set <- dummy_cols(training_set, select_columns = "Users", remove_first_dummy = TRUE)
# PURPOSE : Levels: Communications Earth Observation Navigation Space Science Technology Development
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Purpose", remove_first_dummy = TRUE)
# ORBIT : Levels: Elliptical GEO LEO MEO
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Orbit", remove_first_dummy = TRUE)
# CONTINENT: Levels: Africa Americas Asia Europe Multinational Oceania
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Continent", remove_first_dummy = TRUE)
# training_setset senza Purpose, Users, Continent and Orbit
dummy_training_set <- dummy_training_set[,c(1:2,6:17,19:32)]
names(dummy_training_set)
dummy_training_set <- dummy_cols(training_set, select_columns = "Users", remove_first_dummy = TRUE)
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Purpose", remove_first_dummy = TRUE)
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Orbit", remove_first_dummy = TRUE)
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Continent", remove_first_dummy = TRUE)
names(dummy_training_set)
dummy_training_set <- dummy_training_set[,c(1:2,6:17,19:33)]
library(glmnet)
time <- dummy_training_set$`Effective Lifetime`
status <- dummy_training_set$Status
covariates <-
c(
"Longitude of GEO" ,
"Perigee" ,
"Apogee",
"Eccentricity" ,
"Inclination",
"Period",
"Mass",
"Users_Commercial",
"Users_Government",
"Users_Military",
"Purpose_Earth Observation",
"Purpose_Navigation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Orbit_GEO",
"Orbit_LEO",
"Orbit_MEO",
"Continent_Americas",
"Continent_Asia",
"Continent_Europe",
"Continent_Multinational",
"Continent_Oceania"
)
n_coef = length(covariates)
lambda.grid <- 10^seq(2, -5 ,length = 100)
# Adatta un modello di regressione di Cox penalizzato usando glmnet
# alpha = 1 per la penalizzazione L2 (Ridge)
# alpha = 0 per la penalizzazione L1 (Lasso)
cox_model <- cv.glmnet(x = as.matrix(dummy_training_set[,covariates]), y = Surv(time,status == 'retired'), family = "cox", alpha = 0.2, lambda = lambda.grid)
# PROVA A CAMBIARE VALORE DI ALPHA ---> ELASTIC NET FORSE è MEGLIO
print(cox_model)
bestlambda <- cox_model$lambda.min # con lasso lambda è quasi zero
plot(cox_model)
abline(v=log(bestlambda), lty=1)
fitAtLmin <- glmnet(x = as.matrix(dummy_training_set[,covariates]),  y = Surv(time,status == 'retired') ,family="cox",lambda=bestlambda)
coef <- coef(fitAtLmin)
coef
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Perigee",
"Apogee",
"Inclination",
"Mass",
"Users_Commercial",
"Users_Government",
"Purpose_Earth Observation",
"Purpose_Navigation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Orbit_LEO",
"Continent_Asia"
)
cox1 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox1)
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Perigee",
"Apogee",
"Inclination",
"Mass",
"Users_Commercial",
"Users_Government",
"Purpose_Earth Observation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Orbit_LEO",
"Continent_Asia"
)
cox2 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox2)
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Perigee",
"Apogee",
"Inclination",
"Mass",
"Users_Commercial",
"Users_Government",
"Purpose_Earth Observation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Continent_Asia"
)
cox3 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox3)
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Perigee",
"Apogee",
"Mass",
"Users_Commercial",
"Users_Government",
"Purpose_Earth Observation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Continent_Asia"
)
cox4 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox4)
time <- dummy_training_set$`Effective Lifetime`
Status <- dummy_training_set$Status
variable_sel <-c(  # con coef != 0
"Apogee",
"Mass",
"Users_Commercial",
"Users_Government",
"Purpose_Earth Observation",
"Purpose_Space Science",
"Purpose_Technology Development",
"Continent_Asia"
)
cox5 <- coxph(Surv(time, Status == 'retired') ~ . , data = dummy_training_set[,variable_sel])
summary(cox5)
test <- cox.zph(cox5)
test
cox6 <- coxph(Surv(time, Status == 'retired') ~  Apogee + Mass +Users_Commercial+  Users_Government +
strata(dummy_training_set$`Purpose_Earth Observation`) + dummy_training_set$`Purpose_Space Science`+ dummy_training_set$`Purpose_Technology Development`+ Continent_Asia , data = dummy_training_set)
summary(cox6)
test <- cox.zph(cox6)
test
cox7 <- coxph(Surv(time, Status == 'retired') ~  strata(Apogee) + Mass +Users_Commercial+  Users_Government +
strata(dummy_training_set$`Purpose_Earth Observation`) + dummy_training_set$`Purpose_Space Science`+ dummy_training_set$`Purpose_Technology Development`+ Continent_Asia , data = dummy_training_set)
summary(cox7)
Massa.disc <- cut(training_set$Mass, breaks=c(0, 1000, Inf), labels=c("light", "heavy"))
dummy_training_set$Mass.disc <- Massa.disc
Per.disc <- cut(training_set$Period, breaks=c(0, 500, 1000, Inf), labels=c("short", "medium", "long"))
dummy_training_set$Per.disc <- Per.disc
Inc.disc <- cut(training_set$Inclination, breaks=c(-Inf, 40, 70, Inf), labels=c("low", "medium", "high"))
dummy_training_set$Inc.disc <- Inc.disc
Ap.disc <- cut(training_set$Apogee, breaks=c(0, 25000, Inf), labels=c("low", "high"))
dummy_training_set$Ap.disc <- Ap.disc
Pe.disc <- cut(training_set$Perigee, breaks=c(0, 5000, 25000, Inf), labels=c("low","medium","high"))
dummy_training_set$Pe.disc <- Pe.disc
# MASS: Levels: light heavy
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Mass.disc", remove_first_dummy = TRUE)
# PERIOD: Levels: short medium long
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Per.disc", remove_first_dummy = TRUE)
# INCLINATION: Levels: low medium high
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Inc.disc", remove_first_dummy = TRUE)
# PERIGEE: Levels: low medium high
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Pe.disc", remove_first_dummy = TRUE)
# APOGEE: Levels: low high
dummy_training_set <- dummy_cols(dummy_training_set, select_columns = "Ap.disc", remove_first_dummy = TRUE)
names(dummy_training_set)
217*0.2
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
idna <- which(is.na(data$`Expected Lifetime`))
idna
training_set <- data[idna,]
dim(training_set)
dim(data)[1]
714*0.8
714-140
574-217
sub <- sample(data[-idna,], 357)
data[-idna,]
dim(data[-idna,])
357/497
sub <- data[-idna,]
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.718, list = FALSE)
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
set.seed(123)
idna <- which(is.na(data$`Expected Lifetime`))
training_set0 <- data[idna,]
sub <- data[-idna,]
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.718, list = FALSE)
# Crea il training set utilizzando l'indice
training_set1 <- data[index, ]
#concateno
training_set <- training_set0+training_set1
#concateno
tarining_set <- bind_rows(training_set0, training_set1)
#concateno
training_set <- bind_rows(training_set0, training_set1)
dim(training_set)
test_set <- data[-idna,]
test_set <- test_set[-index,]
dim(test_set)
time <- dummy_data$`Effective Lifetime`
library(readxl)
data <- read_excel("../Dataset/JoinDatasets.xlsx", col_names = TRUE)
set.seed(123)
idna <- which(is.na(data$`Expected Lifetime`))
training_set0 <- data[idna,]
dim(training_set0)
dim(data)
0.8*714
714-140
574-217
dim(sub)
#ci aggiungo altre osservazioni per arrivare all'80% del dataset (ne mancano altre 357)
sub <- data[-idna,] # dataset con expected lifetime
dim(sub)
357/497
0.718*497
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.718, list = FALSE)
length(index)
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.71, list = FALSE)
length(index)
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.712, list = FALSE)
length(index)
index <- createDataPartition(sub$`Effective Lifetime`, p = 0.715, list = FALSE)
length(index)
# Crea il training set utilizzando l'indice
training_set1 <- sub[index,]
dim(training_set1)
#concateno
training_set <- bind_rows(training_set0, training_set1)
dim(training_set)
test_set <- sub[-index, ]
dim(test_set)
View(test_set)
View(training_set)
